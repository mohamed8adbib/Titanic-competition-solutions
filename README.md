# Titanic-competition-solutions
##What is Kaggle?
[Kaggle](https://en.wikipedia.org/wiki/Kaggle) is a platform for predictive modelling and analytics competitions in which statisticians and data miners compete to produce the best models for predicting and describing the datasets uploaded by companies and users. This crowdsourcing approach relies on the fact that there are countless strategies that can be applied to any predictive modelling task and it is impossible to know beforehand which technique or analyst will be most effective.
##What is Titanic competion ?
The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.

One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.

In this challenge, they ask you to complete the analysis of what sorts of people were likely to survive. In particular, they ask you to apply the tools of machine learning to predict which passengers survived the tragedy.
##Goal for this Notebook:
Show a simple example of an analysis of the Titanic disaster in Python using a full complement of PyData utilities. This is aimed for those looking to get into the field or those who are already in the field and looking to see an example of an analysis done with Python.
###This Notebook will show basic examples of:
####Data Handling:
*Importing Data with Pandas
*Cleaning Data
*Exploring Data through Visualizations with Matplotlib
####Data Analysis
*Supervised Machine learning Techniques:
**Logistic Regression Model
**k-nearest neighbors
**Support Vector Machine (SVM) exactely : SVC 
**Random Forest
**Gaussian Naive Bayes
**Perceptron
**Stochastic Gradient Descent
**Decision Tree
####Valuation of the Analysis
**K-folds cross validation to valuate results locally
####Required Libraries:
**[Pandas] (https://pandas.pydata.org/)
**[Numpy] (http://www.numpy.org/)
**[Seaborn] (https://seaborn.pydata.org/)
**[Matplotlib] (https://matplotlib.org/)
**[Scikit-Learn] (http://scikit-learn.org/)
